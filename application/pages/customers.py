"""
üë• Enhanced Customer Analysis - All 4 Tabs with Working Filters
Exact match to customers.html with profiling and RFM segmentation
NOW WITH SMART COLUMN MAPPING for flexibility across data sources
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
from pathlib import Path
import re
from datetime import date, datetime
from datetime import datetime, timedelta


st.set_page_config(
    page_title="Customer Analysis",
    page_icon="üë•",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .main > div { padding-top: 0.5rem; }
    .stat-card {
        background: white;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        border-left: 4px solid;
    }
    .stat-card-primary { border-left-color: #3b82f6; }
    .stat-card-success { border-left-color: #22c55e; }
    .stat-card-warning { border-left-color: #f59e0b; }
    .stat-card-danger { border-left-color: #ef4444; }
    .stat-label {
        font-size: 0.875rem;
        color: #64748b;
        text-transform: uppercase;
        margin-bottom: 8px;
        font-weight: 600;
    }
    .stat-value {
        font-size: 2rem;
        font-weight: 800;
        margin-bottom: 8px;
    }
    .alert {
        padding: 15px 20px;
        border-radius: 6px;
        margin-bottom: 20px;
        border-left: 4px solid;
    }
    .alert-warning {
        background: #fef3c7;
        color: #92400e;
        border-left-color: #f59e0b;
    }
</style>
""", unsafe_allow_html=True)

# ===========================
# COLUMN MAPPINGS
# ===========================

COLUMN_MAPPINGS = {
    # canonical names match the rest of the code: 'customer_id', 'order_id', 'total_amount', 'order_date', etc.
    'customers': {
        'customer_id': ['customer_id', 'CustomerID', 'cust_id', 'custid', 'id', 'ID', 'customer id'],
        'name': ['name', 'customer_name', 'full_name', 'CustomerName', 'fullname'],
        'email': ['email', 'email_address', 'Email', 'e-mail'],
        'phone': ['phone', 'phone_number', 'contact', 'Phone', 'mobile'],
        'address': ['address', 'street_address', 'Address', 'addr'],
        'created_date': ['created_date', 'registration_date', 'signup_date', 'CreatedDate', 'date_joined', 'created'],
        'country': ['country', 'location', 'region', 'Country']
    },
    'orders': {
        'order_id': ['order_id', 'OrderID', 'orderid', 'id', 'ID', 'order_no', 'order number'],
        'customer_id': ['customer_id', 'cust_id', 'CustomerID', 'user_id', 'buyer_id', 'custid'],
        'order_date': ['order_date', 'created_at', 'date', 'OrderDate', 'purchase_date', 'orderdate'],
        'total_amount': ['total_amount', 'amount', 'order_total', 'TotalAmount', 'price', 'total']
    }
}



def get_column(df, table_name, field_name):
    """
    Smart column finder - returns the actual column name from a dataframe
    based on possible variations defined in COLUMN_MAPPINGS
    
    Args:
        df: DataFrame to search
        table_name: Table name (e.g., 'customers', 'orders')
        field_name: Field type (e.g., 'id', 'name', 'email')
    
    Returns:
        str: Actual column name in the dataframe, or None if not found
    """
    if table_name not in COLUMN_MAPPINGS or field_name not in COLUMN_MAPPINGS[table_name]:
        return None
    
    possible_names = COLUMN_MAPPINGS[table_name][field_name]
    
    for col_name in possible_names:
        if col_name in df.columns:
            return col_name
    
    return None

def standardize_dataframe(df, table_name):
    """
    Standardize column names in a dataframe using the mapping
    Returns a copy with standardized column names
    """
    df_copy = df.copy()
    
    if table_name not in COLUMN_MAPPINGS:
        return df_copy
    
    rename_dict = {}
    for standard_name, possible_names in COLUMN_MAPPINGS[table_name].items():
        for possible_name in possible_names:
            if possible_name in df_copy.columns:
                rename_dict[possible_name] = standard_name
                break
    
    if rename_dict:
        df_copy = df_copy.rename(columns=rename_dict)
    
    return df_copy

# ===========================
# GENERATE SAMPLE DATA
# ===========================

@st.cache_data(ttl=600)
def generate_sample_customer_data():
    """Generate sample data with quality issues"""
    np.random.seed(42)
    
    customers = []
    for i in range(1, 1001):
        if i > 100 and np.random.random() < 0.08:
            dup_idx = np.random.randint(1, min(i, 100))
            name = f'Customer {dup_idx}'
            email = f'customer{dup_idx}@example.com'
        else:
            name = f'Customer {i}'
            email = f'customer{i}@example.com'
        
        if np.random.random() < 0.08:
            if np.random.random() < 0.5:
                email = email.replace('@', '')
            else:
                email = email.split('@')[0]
        elif np.random.random() < 0.05:
            email = None
        
        phone = f'+1-555-{np.random.randint(1000, 9999)}'
        if np.random.random() < 0.06:
            phone = '123'
        elif np.random.random() < 0.04:
            phone = None
        
        address = f'{np.random.randint(1, 999)} Main St'
        if np.random.random() < 0.07:
            address = None
        
        customers.append({
            'customer_id': f'C-{i:04d}',
            'name': name,
            'email': email,
            'phone': phone,
            'address': address,
            'created_date': (datetime.now() - timedelta(days=np.random.randint(1, 730))).date()
        })
    
    # Generate orders for profiling
    orders = []
    for i in range(1, 5001):
        orders.append({
            'order_id': i,
            'customer_id': f'C-{np.random.randint(1, 1001):04d}',
            'order_date': (datetime.now() - timedelta(days=np.random.randint(1, 365))).date(),
            'total_amount': np.random.uniform(10, 500)
        })
    
    return pd.DataFrame(customers), pd.DataFrame(orders)

@st.cache_data(ttl=600)
def load_customer_data():
    """
    Smart data loader - tries multiple sources:
    1. CSV Files (PRIORITY)
    2. Sample Data (fallback)
    """
    customers_df = None
    orders_df = None
    source = "Generated Sample Data"
    
    # TRY CSV FILES FIRST
    csv_files = {
        'customers': 'sample_data/core_data/customers.csv',
        'orders': 'sample_data/core_data/orders.csv'
    }
    
    try:
        # Load customers
        if Path(csv_files['customers']).exists():
            customers_df = pd.read_csv(csv_files['customers'])
            # Standardize column names
            customers_df = standardize_dataframe(customers_df, 'customers')
            
            # Clean string columns
            for col in customers_df.select_dtypes(include=['object']).columns:
                customers_df[col] = customers_df[col].astype(str).str.strip()
            
            source = "CSV Files"
            st.sidebar.success(f"‚úÖ Loaded {len(customers_df)} customers from CSV")
        
        # Load orders
        if Path(csv_files['orders']).exists():
            orders_df = pd.read_csv(csv_files['orders'])
            # Standardize column names
            orders_df = standardize_dataframe(orders_df, 'orders')
            
            # Clean string columns
            for col in orders_df.select_dtypes(include=['object']).columns:
                orders_df[col] = orders_df[col].astype(str).str.strip()
            
            st.sidebar.success(f"‚úÖ Loaded {len(orders_df)} orders from CSV")
    except Exception as e:
        st.sidebar.warning(f"‚ö†Ô∏è CSV load error: {str(e)[:60]}")
    
    # Fallback to sample data
    if customers_df is None or orders_df is None:
        st.sidebar.info("üìä Using generated sample data")
        customers_df, orders_df = generate_sample_customer_data()
        source = "Generated Sample Data"
    
    return customers_df, orders_df, source

# ===========================
# ANALYSIS FUNCTIONS (Updated with column mapping)
# ===========================

def analyze_data_quality(df):
    """Analyze quality issues - uses standardized column names"""
    issues = []
    
    # Get column names (should already be standardized)
    id_col = 'customer_id'
    name_col = 'name'
    email_col = 'email'
    phone_col = 'phone'
    address_col = 'address'
    date_col = 'created_date'
    
    # Verify columns exist
    required_cols = [id_col, name_col, email_col, phone_col, address_col, date_col]
    missing_cols = [col for col in required_cols if col not in df.columns]
    
    if missing_cols:
        st.sidebar.error(f"‚ùå Missing columns: {missing_cols}")
        return pd.DataFrame()
    
    for idx, row in df.iterrows():
        customer_issues = []
        severity = "low"
        
        email = row[email_col]
        if pd.isna(email) or email is None or str(email) == 'nan':
            customer_issues.append("Missing Email")
            severity = "critical"
        elif '@' not in str(email) or '.' not in str(email):
            customer_issues.append("Invalid Email Format")
            severity = "high"
        
        phone = row[phone_col]
        if pd.isna(phone) or phone is None or str(phone) == 'nan':
            customer_issues.append("Missing Phone")
            if severity not in ["critical"]:
                severity = "high"
        else:
            phone_digits = ''.join(filter(str.isdigit, str(phone)))
            if len(phone_digits) < 10:
                customer_issues.append("Invalid Phone Format")
                if severity == "low":
                    severity = "medium"
        
        address = row[address_col]
        if pd.isna(address) or address is None or str(address) == 'nan':
            customer_issues.append("Missing Address")
            if severity == "low":
                severity = "medium"
        
        if customer_issues:
            issues.append({
                'Customer ID': row[id_col],
                'Name': row[name_col],
                'Email': row[email_col] if pd.notna(row[email_col]) else '‚ùå Missing',
                'Phone': row[phone_col] if pd.notna(row[phone_col]) else '‚ùå Missing',
                'Address': row[address_col] if pd.notna(row[address_col]) else '‚ùå Missing',
                'Issue': ' & '.join(customer_issues),
                'Severity': severity,
                'Registered': row[date_col]
            })
    
    return pd.DataFrame(issues) if issues else pd.DataFrame()

def detect_duplicates(df):
    """Detect duplicate records - uses standardized column names"""
    duplicates = []
    
    email_col = 'email'
    name_col = 'name'
    
    if email_col not in df.columns or name_col not in df.columns:
        return pd.DataFrame()
    
    email_counts = df[email_col].value_counts()
    email_duplicates = email_counts[email_counts > 1]
    
    for email, count in email_duplicates.head(30).items():
        if pd.notna(email) and str(email) != 'Missing' and str(email) != 'nan':
            matching_rows = df[df[email_col] == email]
            duplicates.append({
                'Duplicate Group': f'DUP-{len(duplicates)+1:03d}',
                'Records': int(count),
                'Customer Name': matching_rows.iloc[0][name_col],
                'Email': email,
                'Match Type': 'Email Match',
                'Confidence': '100%'
            })
    
    name_counts = df[name_col].value_counts()
    name_duplicates = name_counts[name_counts > 1]
    
    for name, count in list(name_duplicates.items())[:15]:
        if pd.notna(name) and not any(d['Customer Name'] == name for d in duplicates):
            matching_rows = df[df[name_col] == name]
            duplicates.append({
                'Duplicate Group': f'DUP-{len(duplicates)+1:03d}',
                'Records': int(count),
                'Customer Name': name,
                'Email': matching_rows.iloc[0][email_col],
                'Match Type': 'Exact Name Match',
                'Confidence': '85%'
            })
    
    return pd.DataFrame(duplicates) if duplicates else pd.DataFrame()

def profile_customers(customers_df, orders_df):
    """Profile customers by segment - uses standardized column names"""
    if len(orders_df) == 0:
        return pd.DataFrame()
    
    # Use standardized column names
    customer_id_col = 'customer_id'
    order_id_col = 'order_id'
    amount_col = 'total_amount'
    
    if customer_id_col not in orders_df.columns:
        return pd.DataFrame()
    
    customer_orders = orders_df.groupby(customer_id_col).agg({
        order_id_col: 'count',
        amount_col: 'sum'
    }).reset_index()
    
    customer_orders.columns = ['customer_id', 'order_count', 'total_revenue']
    
    def segment_customer(row):
        if row['order_count'] >= 10 and row['total_revenue'] >= 1500:
            return 'High Value'
        elif row['order_count'] >= 5:
            return 'Regular'
        elif row['order_count'] >= 1:
            return 'New Customers'
        else:
            return 'At Risk'
    
    customer_orders['segment'] = customer_orders.apply(segment_customer, axis=1)
    
    segment_stats = customer_orders.groupby('segment').agg({
        'customer_id': 'count',
        'total_revenue': 'mean',
        'order_count': 'mean'
    }).reset_index()
    
    segment_stats.columns = ['Segment', 'Customer Count', 'Avg Revenue', 'Avg Orders']
    segment_stats['Avg Revenue'] = '$' + segment_stats['Avg Revenue'].apply(lambda x: f'{x:.0f}')
    segment_stats['Avg Orders'] = segment_stats['Avg Orders'].round(1)
    segment_stats['Retention Rate'] = segment_stats['Segment'].map({
        'High Value': '89%', 'Regular': '67%', 'At Risk': '34%', 'New Customers': '45%'
    })
    
    return segment_stats

def rfm_segmentation(orders_df):
    """RFM segmentation - uses standardized column names"""
    if len(orders_df) == 0:
        return pd.DataFrame()
    
    # Use standardized column names
    customer_id_col = 'customer_id'
    date_col = 'order_date'
    order_id_col = 'order_id'
    amount_col = 'total_amount'
    
    if customer_id_col not in orders_df.columns or date_col not in orders_df.columns:
        return pd.DataFrame()
    
    now = datetime.now()
    orders_df[date_col] = pd.to_datetime(orders_df[date_col], errors='coerce')
    orders_clean = orders_df[orders_df[date_col].notna()].copy()
    
    if len(orders_clean) == 0:
        return pd.DataFrame()
    
    rfm = orders_clean.groupby(customer_id_col).agg({
        date_col: lambda x: (now - x.max()).days,
        order_id_col: 'count',
        amount_col: 'sum'
    }).reset_index()
    
    rfm.columns = ['customer_id', 'recency', 'frequency', 'monetary']
    
    try:
        rfm['r_score'] = pd.qcut(rfm['recency'], 5, labels=[5,4,3,2,1], duplicates='drop')
        rfm['f_score'] = pd.qcut(rfm['frequency'].rank(method='first'), 5, labels=[1,2,3,4,5], duplicates='drop')
        rfm['m_score'] = pd.qcut(rfm['monetary'], 5, labels=[1,2,3,4,5], duplicates='drop')
        
        rfm['rfm_score'] = rfm['r_score'].astype(str) + rfm['f_score'].astype(str) + rfm['m_score'].astype(str)
        
        def rfm_segment(score):
            if score.startswith('5') and score.endswith('5'):
                return 'Champions'
            elif score.startswith('4') or score.startswith('5'):
                return 'Loyal'
            elif score.startswith('3'):
                return 'Potential'
            elif score.startswith('2'):
                return 'At Risk'
            else:
                return 'Lost'
        
        rfm['segment'] = rfm['rfm_score'].apply(rfm_segment)
        
        segment_stats = rfm.groupby('segment').agg({
            'customer_id': 'count',
            'monetary': 'sum'
        }).reset_index()
        
        segment_stats.columns = ['Segment', 'Customers', 'Revenue']
        segment_stats['Revenue'] = '$' + (segment_stats['Revenue'] / 1000000).apply(lambda x: f'{x:.1f}M')
        segment_stats['RFM Score'] = segment_stats['Segment'].map({
            'Champions': '555', 'Loyal': '445-544', 'Potential': '355-454', 'At Risk': '244-344', 'Lost': '111-233'
        })
        segment_stats['Description'] = segment_stats['Segment'].map({
            'Champions': 'Best customers - Frequent, Recent, High Spend',
            'Loyal': 'Consistent purchasers with good spend',
            'Potential': 'Recent customers with growth potential',
            'At Risk': 'Were good, now declining',
            'Lost': "Haven't purchased recently"
        })
        
        return segment_stats[['Segment', 'RFM Score', 'Customers', 'Revenue', 'Description']]
    except Exception as e:
        st.sidebar.error(f"RFM Error: {str(e)[:60]}")
        return pd.DataFrame()

# ===========================
# LOAD DATA
# ===========================

with st.spinner("Loading customer data..."):
    customers_df, orders_df, data_source = load_customer_data()
    quality_issues_df = analyze_data_quality(customers_df)
    duplicates_df = detect_duplicates(customers_df)
    profiling_df = profile_customers(customers_df, orders_df)
    rfm_df = rfm_segmentation(orders_df)

# ===========================
# SIDEBAR FILTERS
# ===========================

with st.sidebar:
    st.markdown("### üìä Data Source")
    st.info(f"**{data_source}**")
    
    st.markdown("---")
    st.markdown("### üë• Filters")
    
    date_range = st.selectbox(
        "üìÖ Date Range",
        ["Last 7 Days", "Last 30 Days", "Last 90 Days", "All Time"],
        index=2
    )
    
    now = datetime.now()
    if date_range == "Last 7 Days":
        cutoff_date = (now - timedelta(days=7)).date()
    elif date_range == "Last 30 Days":
        cutoff_date = (now - timedelta(days=30)).date()
    elif date_range == "Last 90 Days":
        cutoff_date = (now - timedelta(days=90)).date()
    else:
        cutoff_date = None
    
    severity_filter = st.multiselect(
        "üî¥ Severity",
        ["critical", "high", "medium", "low"],
        default=["critical", "high", "medium", "low"]
    )
    
    issue_filter = st.multiselect(
        "üîß Issue Type",
        ["Missing Email", "Invalid Email Format", "Missing Phone", "Invalid Phone Format", "Missing Address"],
        default=["Missing Email", "Invalid Email Format", "Missing Phone", "Invalid Phone Format", "Missing Address"]
    )
    
    search_query = st.text_input("üîç Search", placeholder="Name, Email, ID...")
    
    st.markdown("---")
    if st.button("üîÑ Reset Filters", use_container_width=True):
        st.cache_data.clear()
        st.rerun()

# ===========================
# APPLY FILTERS
# ===========================


def apply_quality_filters(quality_df, date_cutoff=None, severity_filter=None, issue_filter=None, search_query=None, debug=False):
    """
    Robust filtering for quality issues by 'Registered' date and other optional filters.
    Returns a filtered DataFrame (safe on missing/invalid dates).
    """
    if quality_df is None or quality_df.empty:
        return pd.DataFrame()

    df = quality_df.copy()

    # Ensure 'Registered' exists, then coerce to datetime (invalid -> NaT)
    if 'Registered' not in df.columns:
        df['Registered'] = pd.NaT
    else:
        df['Registered'] = pd.to_datetime(df['Registered'], errors='coerce')

    # Convert date_cutoff (various types) to pd.Timestamp or None
    if date_cutoff in (None, ''):
        date_cutoff_ts = None
    else:
        if isinstance(date_cutoff, pd.Timestamp):
            date_cutoff_ts = date_cutoff
        elif isinstance(date_cutoff, datetime):
            date_cutoff_ts = pd.Timestamp(date_cutoff)
        elif isinstance(date_cutoff, date):
            date_cutoff_ts = pd.Timestamp(datetime.combine(date_cutoff, datetime.min.time()))
        else:
            # try parsing string
            try:
                date_cutoff_ts = pd.to_datetime(date_cutoff)
            except Exception:
                date_cutoff_ts = None

    if debug:
        st.sidebar.write("Registered dtype:", df['Registered'].dtype)
        st.sidebar.write("date_cutoff (orig):", repr(date_cutoff))
        st.sidebar.write("date_cutoff (ts):", date_cutoff_ts)
        st.sidebar.write("Registered sample (after parse):", df['Registered'].head().tolist())

    # Apply date filter if cutoff provided
    filtered = df
    if date_cutoff_ts is not None:
        filtered = filtered[filtered['Registered'] >= date_cutoff_ts]

    # Severity filter (if column exists)
    if severity_filter and 'Severity' in filtered.columns:
        if isinstance(severity_filter, str):
            sev = {severity_filter}
        else:
            sev = set(severity_filter)
        filtered = filtered[filtered['Severity'].isin(sev)]

    # Issue filter (if column exists)
    if issue_filter and 'Issue' in filtered.columns:
        if isinstance(issue_filter, str):
            iss = {issue_filter}
        else:
            iss = set(issue_filter)
        filtered = filtered[filtered['Issue'].isin(iss)]

    # Search query across common text columns
    if search_query:
        text_cols = [c for c in ['CustomerName', 'name', 'email', 'notes'] if c in filtered.columns]
        if text_cols:
            mask = False
            for c in text_cols:
                mask = mask | filtered[c].astype(str).str.contains(str(search_query), case=False, na=False)
            filtered = filtered[mask]

    return filtered.reset_index(drop=True)


# ===========================
# HEADER & METRICS
# ===========================

st.title("üë• Customer Analysis")
st.markdown(f"**Customer data quality validation and duplicate detection** ‚Ä¢ Source: {data_source}")

col1, col2, col3, col4 = st.columns(4)

with col1:
    st.markdown('<div class="stat-card stat-card-primary">', unsafe_allow_html=True)
    st.metric("Total Customers", f"{len(customers_df):,}", "+12.5%")
    st.markdown('</div>', unsafe_allow_html=True)

with col2:
    quality_score = ((len(customers_df) - len(quality_issues_df)) / len(customers_df) * 100) if len(customers_df) > 0 else 0
    st.markdown('<div class="stat-card stat-card-success">', unsafe_allow_html=True)
    st.metric("Data Quality Score", f"{quality_score:.1f}%", "+3.2%")
    st.markdown('</div>', unsafe_allow_html=True)

with col3:
    st.markdown('<div class="stat-card stat-card-danger">', unsafe_allow_html=True)
    st.metric("Duplicate Records", f"{len(duplicates_df)}", f"+{max(0, len(duplicates_df) - 40)}")
    st.markdown('</div>', unsafe_allow_html=True)

with col4:
    invalid_emails = len(quality_issues_df[quality_issues_df['Issue'].str.contains('Email', na=False)]) if not quality_issues_df.empty else 0
    st.markdown('<div class="stat-card stat-card-warning">', unsafe_allow_html=True)
    st.metric("Invalid Emails", f"{invalid_emails}", "-15")
    st.markdown('</div>', unsafe_allow_html=True)

st.markdown("---")

# ===========================
# ALERT
# ===========================

if len(duplicates_df) > 0 or invalid_emails > 0:
    st.markdown(f"""
    <div class="alert alert-warning">
        <strong>‚ö†Ô∏è Data Quality Alert:</strong> {len(duplicates_df)} duplicate customer records detected. {invalid_emails} invalid email addresses found.
    </div>
    """, unsafe_allow_html=True)

st.markdown("---")

# ===========================
# TABS - EXACT MATCH TO HTML
# ===========================


filtered_quality = apply_quality_filters(
    quality_issues_df,
    date_cutoff=cutoff_date,
    severity_filter=severity_filter,
    issue_filter=issue_filter,
    search_query=search_query
)

# Duplicate filtering - currently no extra filters applied
filtered_duplicates = duplicates_df.copy() if duplicates_df is not None else pd.DataFrame()


tab1, tab2, tab3, tab4 = st.tabs([
    f"üìã Data Quality Issues ({len(filtered_quality)})",
    f"üîÑ Duplicate Detection ({len(filtered_duplicates)})",
    f"üë§ Customer Profiling",
    f"üéØ RFM Segmentation"
])

# TAB 1: DATA QUALITY ISSUES
with tab1:
    st.subheader("Customer Data Quality Issues")
    
    if len(filtered_quality) > 0:
        st.info(f"Found {len(filtered_quality):,} data quality issues")
        
        display_df = filtered_quality.copy()
        display_df['Severity'] = display_df['Severity'].apply(
            lambda x: f"üî¥ {x.upper()}" if x == "critical"
            else f"üü† {x.upper()}" if x == "high"
            else f"üîµ {x.upper()}" if x == "medium"
            else f"üü¢ {x.upper()}"
        )
        
        st.dataframe(
            display_df[['Customer ID', 'Name', 'Email', 'Phone', 'Address', 'Issue', 'Severity', 'Registered']],
            use_container_width=True,
            hide_index=True,
            height=500
        )
        
        st.caption(f"Showing {len(filtered_quality):,} of {len(quality_issues_df):,} issues")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("üîß Fix Invalid Emails", use_container_width=True):
                st.info("‚úÖ Email validation workflow initiated")
        with col2:
            if st.button("üìû Update Phone Numbers", use_container_width=True):
                st.info("‚úÖ Phone update workflow initiated")
        with col3:
            if st.button("üì• Export Issues", use_container_width=True):
                st.success("‚úÖ Issues exported to CSV")
    else:
        st.success("‚úÖ No data quality issues found!")
        st.balloons()

# TAB 2: DUPLICATE DETECTION
with tab2:
    st.subheader("Duplicate Customer Detection")
    
    if len(filtered_duplicates) > 0:
        total_records = filtered_duplicates['Records'].sum() if 'Records' in filtered_duplicates.columns else 0
        st.info(f"Found {len(filtered_duplicates):,} duplicate groups affecting {total_records:,} records")
        
        st.dataframe(
            filtered_duplicates[['Duplicate Group', 'Records', 'Customer Name', 'Email', 'Match Type', 'Confidence']],
            use_container_width=True,
            hide_index=True,
            height=500
        )
        
        st.caption(f"Total duplicate groups: {len(filtered_duplicates):,}")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üîÄ Merge All Duplicates", use_container_width=True):
                st.success(f"‚úÖ Duplicate merge initiated - {len(filtered_duplicates)} groups will be consolidated")
        with col2:
            if st.button("üì• Export Duplicates", use_container_width=True):
                st.success("‚úÖ Duplicate list exported")
    else:
        st.success("‚úÖ No duplicate records found!")
        st.info("üí° All customer records are unique based on email and name matching.")

# TAB 3: CUSTOMER PROFILING
with tab3:
    st.subheader("Customer Profiling Analysis")
    
    if len(profiling_df) > 0:
        st.dataframe(
            profiling_df,
            use_container_width=True,
            hide_index=True,
            height=300
        )
        
        fig = px.bar(
            profiling_df,
            x='Segment',
            y='Customer Count',
            title='Customer Distribution by Segment',
            color='Customer Count',
            color_continuous_scale='Blues',
            text='Customer Count'
        )
        fig.update_traces(texttemplate='%{text:,}', textposition='outside')
        fig.update_layout(showlegend=False, height=350)
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("#### üí° Segment Insights")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            high_value = profiling_df[profiling_df['Segment'] == 'High Value']['Customer Count'].values
            if len(high_value) > 0:
                st.metric("üíé High Value Customers", f"{high_value[0]:,}")
        with col2:
            at_risk = profiling_df[profiling_df['Segment'] == 'At Risk']['Customer Count'].values
            if len(at_risk) > 0:
                st.metric("‚ö†Ô∏è At Risk Customers", f"{at_risk[0]:,}")
        with col3:
            new = profiling_df[profiling_df['Segment'] == 'New Customers']['Customer Count'].values
            if len(new) > 0:
                st.metric("üÜï New Customers", f"{new[0]:,}")
    else:
        st.info("üìä Customer profiling requires order data.")

# TAB 4: RFM SEGMENTATION
with tab4:
    st.subheader("RFM Customer Segmentation")
    
    if len(rfm_df) > 0:
        st.dataframe(
            rfm_df,
            use_container_width=True,
            hide_index=True,
            height=300
        )
        
        fig = px.treemap(
            rfm_df,
            path=['Segment'],
            values='Customers',
            title='Customer Segments (RFM Analysis)',
            color='Customers',
            color_continuous_scale='RdYlGn'
        )
        fig.update_layout(height=400, margin=dict(l=0, r=0, t=40, b=0))
        st.plotly_chart(fig, use_container_width=True)
        
        st.info("""
        **üìä RFM Scoring Explained:**
        - **Recency (R)**: How recently did customer purchase? (1-5 score)
        - **Frequency (F)**: How often do they purchase? (1-5 score)  
        - **Monetary (M)**: How much do they spend? (1-5 score)
        
        **Champions (555)**: Buy recently, often, spend most  
        **Loyal (4XX-5XX)**: Consistent purchasers with good spend  
        **Potential (3XX)**: Recent customers with growth potential  
        **At Risk (2XX)**: Were good, now declining  
        **Lost (1XX)**: Haven't purchased recently
        """)
    else:
        st.info("üìä RFM segmentation requires order data.")

st.markdown("---")
st.caption(f"Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ‚Ä¢ Data source: {data_source}")