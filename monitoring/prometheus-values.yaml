# Prometheus Stack Configuration for Killercoda
# Values for kube-prometheus-stack Helm chart
# Optimized for Killercoda resource constraints

# Prometheus Operator
prometheusOperator:
  enabled: true
  resources:
    requests:
      cpu: 50m       # Reduced for Killercoda
      memory: 64Mi   # Reduced for Killercoda
    limits:
      cpu: 100m
      memory: 128Mi

# Prometheus Server
prometheus:
  enabled: true
  prometheusSpec:
    # Retention period (reduced for Killercoda)
    retention: 7d           # Reduced from 15d for Killercoda
    retentionSize: "5GB"    # Reduced from 10GB for Killercoda
    
    # Resource limits (optimized for Killercoda)
    resources:
      requests:
        cpu: 250m      # Reduced for Killercoda
        memory: 512Mi  # Reduced for Killercoda
      limits:
        cpu: 500m      # Reduced for Killercoda
        memory: 1Gi    # Reduced for Killercoda
    
    # Storage (using Killercoda's local-path)
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: local-path  # Killercoda storage class
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi  # Reduced from 20Gi for Killercoda
    
    # Service monitors to discover
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    
    # Scrape interval
    scrapeInterval: 15s
    evaluationInterval: 15s
    
    # External labels
    externalLabels:
      cluster: killercoda      # Changed from minikube
      environment: dev

# Grafana
grafana:
  enabled: true
  
  # Admin credentials
  adminPassword: admin123  # CHANGE IN PRODUCTION!
  
  # Persistence (using Killercoda storage)
  persistence:
    enabled: true
    storageClassName: local-path  # Killercoda storage class
    size: 2Gi  # Reduced from 5Gi for Killercoda
  
  # Resources (optimized for Killercoda)
  resources:
    requests:
      cpu: 50m       # Reduced for Killercoda
      memory: 64Mi   # Reduced for Killercoda
    limits:
      cpu: 100m
      memory: 128Mi
  
  # Service type (ClusterIP for port-forward access)
  service:
    type: ClusterIP  # Changed from NodePort for Killercoda
    port: 80
  
  # Datasources
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          url: http://prometheus-operated:9090
          access: proxy
          isDefault: true
  
  # Dashboard providers
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'default'
          orgId: 1
          folder: ''
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default
  
  # Pre-installed dashboards
  dashboards:
    default:
      # Kubernetes cluster monitoring
      kubernetes-cluster:
        gnetId: 7249
        revision: 1
        datasource: Prometheus
      
      # Node exporter
      node-exporter:
        gnetId: 1860
        revision: 27
        datasource: Prometheus
      
      # Kubernetes pods
      kubernetes-pods:
        gnetId: 6417
        revision: 1
        datasource: Prometheus

# AlertManager
alertmanager:
  enabled: true
  alertmanagerSpec:
    # Resources (optimized for Killercoda)
    resources:
      requests:
        cpu: 25m      # Reduced for Killercoda
        memory: 32Mi  # Reduced for Killercoda
      limits:
        cpu: 50m
        memory: 64Mi
    
    # Storage (using Killercoda storage)
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: local-path  # Killercoda storage class
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 1Gi  # Reduced from 2Gi for Killercoda
  
  # AlertManager configuration
  config:
    global:
      resolve_timeout: 5m
    
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'null'
      routes:
        - match:
            alertname: Watchdog
          receiver: 'null'
        - match:
            severity: critical
          receiver: 'critical-alerts'
        - match:
            severity: warning
          receiver: 'warning-alerts'
    
    receivers:
      - name: 'null'
      - name: 'critical-alerts'
        # Add your notification channels here
        # webhook_configs:
        #   - url: 'http://your-webhook-url'
      - name: 'warning-alerts'
        # webhook_configs:
        #   - url: 'http://your-webhook-url'

# Node Exporter
nodeExporter:
  enabled: true

# Kube State Metrics
kubeStateMetrics:
  enabled: true

# Default rules
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: false
    configReloaders: true
    general: true
    k8s: true
    kubeApiserverAvailability: true
    kubeApiserverSlos: true
    kubelet: true
    kubeProxy: false
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeScheduler: false
    kubeStateMetrics: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true
